MODE: 1             # 1: train, 2: test, 3: eval
MODEL: 1            # 2: train the inpaint model 3: load transformer, train encoder and decoder 5: train transformer 6: train reconstructor 
SEED: 10            # random seed
GPU: [1]            # list of gpu ids
DEBUG: 0            # turns on debugging mode
VERBOSE: 0          # turns on verbose mode in the output console
TEST_MODE: pair_test     # hazy, clean, pair_test
#TRAIN_HAZY_FLIST: ./datasets/syn_reside_train_hazy.flist
#TRAIN_CLEAN_FLIST: ./datasets/syn_reside_train_clean.flist
TRAIN_CLEAN_FLIST: /home/ubuntu/D4-main_test/datasets/its_train_gt.flist
TRAIN_HAZY_FLIST: /home/ubuntu/D4-main_test/datasets/its_train_hazy.flist
TRAIN_TRANSMISSION_FLIST: /home/ubuntu/D4-main_test/datasets/reside_train_transmission_indoor.flist
#TEST_HAZY_FLIST: /home/ubuntu/D4/D4-main_3/datasets/sots_test_hazy_indoor.flist
#TEST_HAZY_FLIST: ./datasets/reside_test_hazy.flist
TEST_HAZY_FLIST: /home/ubuntu/D4-main_test/datasets/sots_test_hazy_indoor.flist
TEST_CLEAN_FLIST: /home/ubuntu/D4-main_test/datasets/sots_test_clear_indoor.flist  
TEST_CLEAN_PATH: /home/ubuntu/D4-main_test/test_data/SOTS/indoor/nyuhaze500/gt
VAL_HAZY_FLIST: /home/ubuntu/D4-main_test/datasets/sots_test_hazy_indoor.flist
VAL_CLEAN_PATH: /home/ubuntu/D4-main_test/test_data/SOTS/indoor/nyuhaze500/gt







# #TRAIN_HAZY_FLIST: ./datasets/syn_reside_train_hazy.flist
# #TRAIN_CLEAN_FLIST: ./datasets/syn_reside_train_clean.flist
# TRAIN_CLEAN_FLIST: ./datasets/reside_train_clean_indoor.flist
# TRAIN_HAZY_FLIST: ./datasets/reside_train_hazy_indoor.flist
# TRAIN_TRANSMISSION_FLIST: ./datasets/reside_train_transmission_indoor.flist


# TEST_HAZY_FLIST: ./datasets/sots_test_hazy.flist
# #TEST_HAZY_FLIST: ./datasets/reside_test_hazy.flist
# TEST_HAZY_FLIST: ./datasets/sots_test_hazy_indoor.flist
# TEST_CLEAN_PATH: /home/yangyang/dataset/RESIDE_part_429_indoor/test_gt


# VAL_HAZY_FLIST: ./datasets/sots_test_hazy_indoor.flist
# VAL_CLEAN_PATH: /home/yangyang/dataset/RESIDE_part_429_indoor/test_gt 



LR: 0.0001 
WEIGHT_DECAY: 0                   # learning rate
D2G_LR: 0.1                   # discriminator/generator learning rate ratio
BETA1: 0.9                    # adam optimizer beta1
BETA2: 0.999                    # adam optimizer beta2
BATCH_SIZE: 2                 # input batch size for training1
CROP_SIZE: 256               # input image size for training 0 for original size
SIGMA: 50                      # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)
MAX_ITERS: 120000                # maximum number of iterations to train the model
BASE_CHANNEL_NUM: 64
BLOCK_NUM: 4

PSNR: RGB
L1_LOSS_WEIGHT: 1             # l1 loss weight
CONTENT_LOSS_WEIGHT: 0.1      # perceptual loss weight
INPAINT_ADV_LOSS_WEIGHT: 0.1  # adversarial loss weight

MIN_BETA: 0.6
MAX_BETA: 1.8
MIN_D: 0.2
MAX_D: 5

GAN_LOSS_WEIGHT: 0.2
PERCEPTUAL_LOSS_WEIGHT: 0.0001
CYCLE_LOSS_WEIGHT: 1 
DARK_CHANNEL_LOSS_WEIGHT: 0.05
#TRANSMISSION_PENALTY_LOSS_WEIGHT: 0.01
ONEWAY_HUE_LOSS_WEIGHT: 0
VERTICAL_LOSS_WEIGHT: 0
TV_LOSS_WEIGHT: 0
IDENTITY_LOSS_WEIGHT: 0
DEPTH_LOSS_WEIGHT: 0.5
CORR_LOSS_WEIGHT: 0
PARA_LOSS_WEIGHT: 1
TRANSMISSION_PENALTY_LOSS_WEIGHT: 3
HAZE_COLOR_LOSS_WEIGHT: 1
CLEAN_SCENE_LOSS_WEIGHT: 0.1
GRAY_WORLD_LOSS_WEIGHT: 0


GAN_LOSS: lsgan               # nsgan | lsgan | hinge
GAN_POOL_SIZE: 0              # fake images pool size

SAVE_INTERVAL: 2000           # how many iterations to wait before saving model (0: never)
SAMPLE_INTERVAL: 50        # how many iterations to wait before sampling (0: never)
SAMPLE_SIZE: 4               # number of images to sample
EVAL_INTERVAL: 2000              # how many iterations to wait before model evaluation (0: never)
LOG_INTERVAL: 100              # how many iterations to wait before logging training status (0: never)
